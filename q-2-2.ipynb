{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"AdmissionDataset/data.csv\")\n",
    "    # df[df['Chance of Admit ']<0.5]=0\n",
    "    # df[df['Chance of Admit ']>=0.5]=1\n",
    "X =df.drop(['Chance of Admit ','Serial No.'],axis=1)\n",
    "y=df['Chance of Admit ']\n",
    "# df\n",
    "thres=0.5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "knntrain=copy.deepcopy(X_train)\n",
    "knntest=copy.deepcopy(X_test)\n",
    "knnytrain=copy.deepcopy(y_train)\n",
    "knnytest=copy.deepcopy(y_test)\n",
    "X_train = (X_train - X_train.mean())/X_train.std()\n",
    "X_test = (X_test - X_test.mean())/X_test.std()\n",
    "y_train=list(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]>thres:\n",
    "        y_train[i]=1\n",
    "    else:\n",
    "        y_train[i]=0\n",
    "y_train=pd.DataFrame({'Chance of Admit ':y_train\n",
    "\n",
    "})\n",
    "y_test=list(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]>thres:\n",
    "        y_test[i]=1\n",
    "    else:\n",
    "        y_test[i]=0\n",
    "y_test=pd.DataFrame({'Chance of Admit ':y_test\n",
    "\n",
    "})\n",
    "\n",
    "features=['GRE Score','TOEFL Score','University Rating','SOP','LOR ','CGPA','Research']\n",
    "#     intrain=X_train\n",
    "#     intest=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train,X_test,y_train,y_test):\n",
    "#     thres=0.4\n",
    "    \n",
    "    # y_train\n",
    "\n",
    "    def grad(thetaT):\n",
    "        return 1/(1+np.exp(-thetaT))\n",
    "\n",
    "\n",
    "    my_data=pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "    X=X_train\n",
    "\n",
    "    ones = np.ones([X.shape[0],1])\n",
    "\n",
    "\n",
    "    X = np.concatenate((ones,X),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    y=pd.DataFrame(y_train)\n",
    "    y=y.values\n",
    "    # y\n",
    "\n",
    "    theta = np.zeros([1,8])\n",
    "\n",
    "\n",
    "    alpha = 0.01\n",
    "\n",
    "    iters = 1000\n",
    "\n",
    "    def gradientDescent(X,y,theta,iters,alpha):\n",
    "        for i in range(iters):\n",
    "            theta = theta - (alpha/len(X)) * np.sum(X * (grad(X @ theta.T) - y), axis=0)\n",
    "\n",
    "        return theta\n",
    "\n",
    "    #running the gd and cost function\n",
    "\n",
    "    g = gradientDescent(X,y,theta,iters,alpha)\n",
    "    betaList=g[0]\n",
    "    ones = np.ones([X_test.shape[0],1])\n",
    "    X_test = np.concatenate((ones,X_test),axis=1)\n",
    "\n",
    "    y_pred=grad(X_test@betaList)\n",
    "\n",
    "    y_pred=list(y_pred)\n",
    "#     print(y_pred)\n",
    "    df=pd.DataFrame({'Admit':y_pred})\n",
    "\n",
    "    df[df['Admit']<=thres]=0\n",
    "    df[df['Admit']>thres]=1\n",
    "#     print(df)\n",
    "    y_pred=list(df['Admit'])\n",
    "\n",
    "\n",
    "#     print(confusion_matrix(y_test, y_pred))  \n",
    "    print(\"-------------------Logistic Accuracy Score-------------------------\")\n",
    "    print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y): \n",
    "#row by row i.e all features resultant euclid distance in single line\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid(k,X_train,X_test,y_train,y_test):\n",
    "    y_res=[]\n",
    "    for index,row in X_test.iterrows():\n",
    "        result=[]\n",
    "        for index1,row1 in X_train.iterrows():\n",
    "                result.append(euclidean_distance(row,row1))\n",
    "        df1=pd.DataFrame(\n",
    "        {\n",
    "            'dist':result,\n",
    "            'class':y_train\n",
    "        })\n",
    "#         print(df1)\n",
    "        df1=df1.sort_values(by=['dist'])\n",
    "        count=0;\n",
    "#         k=5\n",
    "        classVote={}\n",
    "        max1=0\n",
    "        res=\"\"\n",
    "        for index1,row1 in df1.iterrows():\n",
    "            capital=row1['class']\n",
    "            if capital > thres:\n",
    "                capital=1\n",
    "            else:\n",
    "                capital=0\n",
    "            count=count+1\n",
    "            if  capital in classVote:\n",
    "                classVote[capital] = classVote[capital]+1\n",
    "            else:\n",
    "                classVote[capital]=1\n",
    "            if classVote[capital]>=max1:\n",
    "                res=capital\n",
    "                max1=classVote[capital]\n",
    "            if count==k:\n",
    "                break;\n",
    "        y_res.append(res)\n",
    "    return y_res,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Logistic Accuracy Score-------------------------\n",
      "Accuracy:  0.9222222222222223\n"
     ]
    }
   ],
   "source": [
    "logistic(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------KNN AccuracyScore------------------------\n",
      "Accuracy:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "y_res,y_test=euclid(5,knntrain,knntest,knnytrain,knnytest)\n",
    "y_test=list(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]>thres:\n",
    "        y_test[i]=1\n",
    "    else:\n",
    "        y_test[i]=0\n",
    "print(\"---------------------KNN AccuracyScore------------------------\")\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
